{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e2c21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 14969\n",
      "Validation set size: 1871\n",
      "Test set size: 1871\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import *\n",
    "from lircst_ana_dataset import LircstAnaDataset\n",
    "from torch import Generator\n",
    "\n",
    "dataset = LircstAnaDataset('/home/samnub/dev/lircst-ana/data/')\n",
    "\n",
    "rand_generator = Generator().manual_seed(42) # The meaning of life, the universe and everything\n",
    "\n",
    "dataset_train, dataset_valid, dataset_test = random_split(dataset, [0.8, 0.1, 0.1], generator=rand_generator)\n",
    "\n",
    "print(f\"Train set size: {len(dataset_train)}\")\n",
    "print(f\"Validation set size: {len(dataset_valid)}\")\n",
    "print(f\"Test set size: {len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2215057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"ECD-Phys\": {\n",
    "        \"train_dataset\": dataset_train,\n",
    "        \"valid_dataset\": None,\n",
    "        \"test_dataset\": dataset_test,\n",
    "        \"physics\": True,  # Use physics-based loss\n",
    "        \"latent\": False,  # Don't use latent diffusion\n",
    "    },\n",
    "    \"ECD\": {\n",
    "        \"train_dataset\": dataset_train,\n",
    "        \"valid_dataset\": None,\n",
    "        \"test_dataset\": dataset_test,\n",
    "        \"physics\": False,  # Don't use physics-based loss\n",
    "        \"latent\": False,  # Don't use latent diffusion\n",
    "    },\n",
    "    \"ECLD-Phys\": {\n",
    "        \"train_dataset\": dataset_train,\n",
    "        \"valid_dataset\": None,\n",
    "        \"test_dataset\": dataset_test,\n",
    "        \"physics\": True,  # Use physics-based loss\n",
    "        \"latent\": True,  # Use latent diffusion\n",
    "    },\n",
    "    \"ECLD\": {\n",
    "        \"train_dataset\": dataset_train,\n",
    "        \"valid_dataset\": None,\n",
    "        \"test_dataset\": dataset_test,\n",
    "        \"physics\": False,  # Don't use physics-based loss\n",
    "        \"latent\": True,  # Use latent diffusion\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b633f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samnub/anaconda3/envs/lircst-diffusion/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ECD-Phys...\n",
      "Is Time embed used ?  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samnub/dev/lircst-diffusion/src/Diffusion/EMA.py:58: UserWarning: EMA has better performance when Apex is installed: https://github.com/NVIDIA/apex#installation.\n",
      "  rank_zero_warn(\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                        | Params | Mode \n",
      "----------------------------------------------------------------------\n",
      "0 | model         | EncodedConditionalDiffusion | 56.6 M | train\n",
      "1 | physics_model | PhysicsIncorporated         | 0      | train\n",
      "----------------------------------------------------------------------\n",
      "56.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "56.6 M    Total params\n",
      "226.463   Total estimated model params size (MB)\n",
      "262       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|â–‰         | 92/936 [00:41<06:23,  2.20it/s, v_num=0, train_loss=0.141] "
     ]
    }
   ],
   "source": [
    "# Full pipeline\n",
    "from encoded_conditional_diffusion import ECDiffusion\n",
    "from util import generate_directory_name, get_latest_ckpt\n",
    "\n",
    "\n",
    "# Setup Diffusion modules\n",
    "import pytorch_lightning as pl\n",
    "from Diffusion.EMA import EMA\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "pre_load: bool = False # Load the latest checkpoint if available\n",
    "train_mode: bool = True\n",
    "test_afterward: bool = True\n",
    "\n",
    "def train():\n",
    "    for name, model_arg in model_args.items():\n",
    "        print(f\"Training {name}...\")\n",
    "\n",
    "        model = ECDiffusion(**model_arg)\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=200,\n",
    "            max_steps=2e5,\n",
    "            callbacks=[EMA(0.9999)],\n",
    "            accelerator='gpu',\n",
    "            devices=[0],\n",
    "            num_sanity_val_steps=0,  # Disable sanity check on dataloader\n",
    "            default_root_dir=generate_directory_name(name, get_latest_ckpt(name)[1] if pre_load else None),\n",
    "        )\n",
    "        \n",
    "        trainer.fit(model, ckpt_path=get_latest_ckpt(name)[0] if pre_load else None)\n",
    "        \n",
    "        if test_afterward:\n",
    "            trainer.test(model, ckpt_path=get_latest_ckpt(name)[0] if pre_load else None)\n",
    "\n",
    "if train_mode:\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c270d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some samples from each model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from encoded_conditional_diffusion import ECDiffusion\n",
    "from util import get_latest_ckpt\n",
    "\n",
    "def show_samples(model: ECDiffusion, dataset_idx: int|None=None, num_samples=4):\n",
    "    phan, sino, _ = dataset_test[np.random.randint(0, len(dataset_test)) if dataset_idx is None else dataset_idx]\n",
    "    #sino = torch.from_numpy(sino)\n",
    "    batch_input = torch.stack(num_samples*[sino]).cuda()\n",
    "\n",
    "    out, encoded_condition = model(batch_input, verbose=True)\n",
    "\n",
    "    # Pre-process our data to be consistently -1 to 1 scaled\n",
    "    phan = model.preprocess(image=phan.unsqueeze(0))[0].squeeze(0)\n",
    "    #out, _ = model.preprocess(image=out) # If the model is trained right, this should not be necessary\n",
    "\n",
    "    # print min and max values of the output\n",
    "    print(f\"Output min: {out.min().item()}, max: {out.max().item()}\")\n",
    "    print(f\"Encoded condition min: {encoded_condition.min().item()}, max: {encoded_condition.max().item()}\")\n",
    "    print(f\"Phan min: {phan.min().item()}, max: {phan.max().item()}\")\n",
    "\n",
    "    plt.figure(dpi=800)\n",
    "    plt.subplot(1,3+len(out)*2,1)\n",
    "    plt.imshow(torch.sum(sino, axis=2))\n",
    "    plt.title('Input')\n",
    "    plt.axis('off')\n",
    "    for idx in range(out.shape[0]*3):\n",
    "        if idx % 3 == 1:\n",
    "            continue\n",
    "        if idx % 3 == 2:\n",
    "            continue\n",
    "        plt.subplot(1,3+len(out)*3,idx+2)\n",
    "        plt.imshow(torch.sum(encoded_condition[idx//3].detach().cpu(), axis=0))\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,3+len(out)*3,idx+3)\n",
    "        plt.imshow(out[idx//3].detach().cpu()[0])\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,3+len(out)*3,idx+4)\n",
    "        plt.imshow(out[idx//3].detach().cpu()[-1])\n",
    "        plt.axis('off')\n",
    "    plt.subplot(1,3+len(out)*3,2+len(out)*3)\n",
    "    plt.imshow(phan[0].cpu())\n",
    "    plt.title('S')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3+len(out)*3,3+len(out)*3)\n",
    "    plt.imshow(phan[1].cpu())\n",
    "    plt.title('A')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    def compare_images(imageA, imageB):\n",
    "        # Compute SSIM between two images, and PSNR\n",
    "        \n",
    "        # If images aren't the same size, resize them\n",
    "        if imageA.shape != imageB.shape:\n",
    "            imageA = F.interpolate(imageA, size=imageB.shape[-2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        # P.S. Scikit-image returns a value between -1 and 1, where 1 is a perfect match and -1 is a complete mismatch\n",
    "        s = ssim(imageA, \n",
    "                imageB, \n",
    "                multichannel=True,\n",
    "                data_range=imageB.max() - imageB.min())\n",
    "        \n",
    "        p = psnr(imageA, imageB, data_range=imageB.max() - imageB.min())\n",
    "\n",
    "        return s, p\n",
    "    \n",
    "    print(\"SSIM, PSNR:\")\n",
    "    for idx in range(len(out)):\n",
    "        print(f\"Scatter channel: {compare_images(out[idx].detach().cpu().numpy()[0], phan[0].cpu().numpy())}\")\n",
    "        print(f\"Attenuation channel: {compare_images(out[idx].detach().cpu().numpy()[-1], phan[1].cpu().numpy())}\")\n",
    "\n",
    "random_idx = np.random.randint(0, len(dataset_test))\n",
    "print(f\"Random dataset index: {random_idx}\")\n",
    "\n",
    "for name, model_arg in model_args.items():\n",
    "    print(f\"Showing samples for {name}...\")\n",
    "\n",
    "    model = ECDiffusion.load_from_checkpoint(\n",
    "        get_latest_ckpt(name)[0],\n",
    "        **model_arg\n",
    "    ).cuda()\n",
    "\n",
    "    show_samples(model, dataset_idx=random_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lircst-diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
